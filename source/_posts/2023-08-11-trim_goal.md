---
layout: post	
title: "测序数据处理自用笔记"	
date: 2023-08-11 10:00:05	
updated: 2023-08-11 10:57:21	
excerpt: "列一下知识前置"	
categories: 
- 学习
- 生物信息学
tag: 
- 学习
- 生物信息学
mermaid: true
typora-root-url: ..
---



# 转录组数据处理笔记

## 一、前置环境

### 1.1 Linux子系统

首先肯定是在Linux上进行，我这边稍微记录一下现在装Linux子系统的步骤[^1]：

以管理员模式运行Windows terminal，并执行以下指令：

```powershell
wsl --install
```



安装完毕后，再次运行此指令，能够看到如下界面：

![wsl分支](/images/posts/trim_goal/wsl分支.png)



接下来根据提示，安装指定的分支，例如我选择Ubuntu22：

```powershell
wsl --install -d Ubuntu-22.04
```

运行期间会要求输入用户名密码等，跟着输入就行。



### 1.2 conda安装及镜像配置

首先安装miniconda[^2]，下载安装脚本，并赋予其相应权限，之后运行脚本即可：

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
sudo chmod 777 Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
./Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
```

> 具体文件名字视你下的版本而定

脚本运行期间，基本上是一路yes到底就行了。

conda安装完毕之后，重启系统或者通过一下指令刷新环境变量：

```bash
source .bashrc
```





接下来配置所使用的镜像[^3]，这里需要使用bioconda这个channel：

```bash
conda config --set show_channel_urls yes
nano .condarc
```

将配置文件修改如下：

```yaml
channels:
  - defaults
show_channel_urls: true
default_channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda
custom_channels:
  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/
```

之后使用如下指令来清空缓存：

```bash
conda clean -i
```

现在可以创建一个新的环境了：

```bash
conda create --name bioinfo python=3.10
conda activate bioinfo
```



![](/images/posts/trim_goal/conda.png)



## 二、质量分析

这里所使用到的软件为fastqc与multiqc，这俩其实用处差不多，只不过后者可以将多份数据进行整合。

### 2.1 软件安装

直接通过conda安装即可：

```bash
conda install fastqc multiqc
```



### 2.2 参数含义



#### FastQC

- `-h` 或 `--help` ：显示帮助信息
- `-o <output_dir>` 或 `--outdir <output_dir>`：指定输出目录，将生成的结果文件保存到指定的目录中
- `-f <format>` 或 `--format <format>`：指定输入文件的格式。常见的格式包括"fastq"、"bam"、"sam"等
- `-t <threads>` 或 `--threads <threads>`：指定线程数，用于加速分析。默认为1个线程
- `-c <config_file>` 或 `--config <config_file>`：指定配置文件，配置额外的参数等
- `-k <kmersize>` 或 `--kmersize <kmersize>`：指定用于检测存在的最大k-mer大小。默认为10
- `-adapters <adapters_file>`：指定adapter序列文件，用于adapter污染检测
- `-limits <limits_file>`：指定limits文件，用于制定可接受的范围，例如序列长度、GC含量等
- `-extract`：提取原始的FastQC zip文件，而不进行分析
- `-q` 或 `--quiet`：静默模式，只输出错误消息



#### MultiQC

- `-h` 或 `--help` ：显示帮助信息。
- `-o <output_dir>` 或 `--outdir <output_dir>`：指定输出目录，将生成的报告文件保存到指定的目录中。
- `-c <config_file>` 或 `--config <config_file>`：指定配置文件，自定义报告生成的规则和设置。
- `-s` 或 `--fullnames`：显示完整的样本名称，而不仅仅是文件名部分。
- `--title <report_title>`：指定报告的标题。
- `-f` 或 `--force`：强制重新生成报告，覆盖已存在的报告文件。
- `--ignore <regexp>`：忽略与指定正则表达式匹配的文件。
- `--exclude <regexp>`：排除与指定正则表达式匹配的文件。
- `--no-ansi`：禁用ANSI转义序列，不使用彩色输出。
- `-q` 或 `--quiet`：静默模式，只输出错误消息。



### 2.3 质量检测

由于这两个软件都无法自动创建目录，因此需要手动创建输出目录：

```bash
mkdir result
```

对于单个文件，使用fastqc进行分析，如：

```bash
fastqc -o result -f fastq -t 8 raw_data/H1_1.fq.gz
```

即可得到分析结果：

![](/images/posts/trim_goal/fastC结果.png)

批量处理一个文件夹下的数据：

```bash
cd raw_data
ls *.gz |xargs fastqc -o ../result/ -t 8
```



同时，可以使用MultiQC对多个数据文件进行整合：

```bash
multiqc -o result/ result/
```

![](/images/posts/trim_goal/multiqc result.png)





## 三、数据清洗

### 3.1 软件安装

数据清洗使用的软件为Trim Galore，它前置依赖Cutadapt和FastQC

```bash
conda install cutadapt trim-galore
```



### 3.2 参数含义

#### Trim Galore

- `--quality`：指定去除低质量reads的阈值，默认为20。 作用：去除质量低于指定阈值的reads
- `--length`：指定去除短reads的长度阈值，默认为20。 作用：去除长度低于指定阈值的reads
- `--stringency`：指定adapter剪切的严格程度，默认为1。 作用：调整adapter剪切的严格程度，值越高表示更严格的剪切
- `--paired`：指定输入的测序数据是否为配对的，默认为单端测序。 作用：指定处理的测序数据是否为配对的，以决定是否进行配对数据处理
- `--phred33`：：选择phred33或者phred64，表示测序平台使用的Phred quality score
- `--fastqc`：生成每个输入文件的质量评估报告，同时内部调用fastqc软件。 作用：生成测序数据的质量评估报告，以便进行质量控制
- `--fastqc_args "<ARGS>"` fastqc的参数
- `--gzip`：指定输出文件是否进行压缩，默认为否。 作用：选择是否对输出文件进行压缩，可以减小文件大小
- `--cores`：指定使用的CPU核心数，默认为1。 作用：指定trim-galore使用的CPU核心数，用于加速处理速度
- `--output_dir`：输入目录。需要提前建立目录，否则运行会报错



### 3.3 清洗

```bash
mkdir clean_data
mkdir clean_result
```

对于单个文件：

```bash
trim_galore --paired --cores 2 --phred33 --length 35 --stringency 1 --quality 25 --gzip --fastqc_args "-o trim_result/ -f fastq -t 8" --output_dir after_trim/ raw_data/H1_1.fq.gz raw_data/H1_2.fq.gz
```



批量处理：

```bash
mkdir clean_data
mkdir clean_result

ls raw_data/*_1.fq.gz > 1
ls raw_data/*_2.fq.gz > 2

paste 1 2 >config

cat config | while read id
  do
    arr=($id)
    fq1=${arr[0]}
    fq2=${arr[1]}
    trim_galore --paired --cores 2 --phred33 --length 35 --stringency 1 --quality 25 --gzip --fastqc_args "-o clean_result/ -f fastq -t 8" --output_dir clean_data/  $fq1 $fq2
  done

rm 1
rm 2
rm config

multiqc -o clean_result/ clean_result/

echo "done"
```



## 参考

[^1]: [https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)
[^2]: [https://conda.io/projects/conda/en/stable/user-guide/install/index.html](https://conda.io/projects/conda/en/stable/user-guide/install/index.html)
[^3]: [https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/](https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/)

