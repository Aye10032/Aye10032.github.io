---
layout: post	
title: "测序数据处理自用笔记"	
date: 2023-08-11 10:00:05	
updated: 2023-08-11 10:57:21	
excerpt: "主要记点参数脚本什么的"	
categories: 
- 学习
- 生物信息学
tag: 
- 学习
- 生物信息学
mermaid: true
typora-root-url: ..
---



# 转录组数据处理笔记

## 一、前置环境

### 1.1 Linux子系统

首先肯定是在Linux上进行，我这边稍微记录一下现在装Linux子系统的步骤[^1]：

以管理员模式运行Windows terminal，并执行以下指令：

```powershell
wsl --install
```



安装完毕后，再次运行此指令，能够看到如下界面：

![wsl分支](/images/posts/trim_goal/wsl分支.png)



接下来根据提示，安装指定的分支，例如我选择Ubuntu22：

```powershell
wsl --install -d Ubuntu-22.04
```

运行期间会要求输入用户名密码等，跟着输入就行。



### 1.2 conda安装及镜像配置

首先安装miniconda[^2]，下载安装脚本，并赋予其相应权限，之后运行脚本即可：

```bash
wget https://repo.anaconda.com/miniconda/Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
sudo chmod 777 Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
./Miniconda3-py310_23.5.2-0-Linux-x86_64.sh
```

> 具体文件名字视你下的版本而定

脚本运行期间，基本上是一路yes到底就行了。

conda安装完毕之后，重启系统或者通过一下指令刷新环境变量：

```bash
source .bashrc
```





接下来配置所使用的镜像[^3]，这里需要使用bioconda这个channel：

```bash
conda config --set show_channel_urls yes
nano .condarc
```

将配置文件修改如下：

```yaml
channels:
  - defaults
show_channel_urls: true
default_channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda
custom_channels:
  conda-forge: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  msys2: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  bioconda: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  menpo: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  pytorch-lts: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  simpleitk: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud
  deepmodeling: https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/
```

之后使用如下指令来清空缓存：

```bash
conda clean -i
```

现在可以创建一个新的环境了：

```bash
conda create --name bioinfo python=3.10
conda activate bioinfo
```



![](/images/posts/trim_goal/conda.png)



## 二、质量分析

这里所使用到的软件为fastqc与multiqc，这俩其实用处差不多，只不过后者可以将多份数据进行整合。

### 2.1 软件安装

直接通过conda安装即可：

```bash
conda install fastqc multiqc
```



### 2.2 参数含义



#### FastQC[^4]

- `-h` 或 `--help` ：显示帮助信息
- `-o <output_dir>` 或 `--outdir <output_dir>`：指定输出目录，将生成的结果文件保存到指定的目录中
- `-f <format>` 或 `--format <format>`：指定输入文件的格式。常见的格式包括"fastq"、"bam"、"sam"等
- `-t <threads>` 或 `--threads <threads>`：指定线程数，用于加速分析。默认为1个线程
- `-c <config_file>` 或 `--config <config_file>`：指定配置文件，配置额外的参数等
- `-k <kmersize>` 或 `--kmersize <kmersize>`：指定用于检测存在的最大k-mer大小。默认为10
- `-adapters <adapters_file>`：指定adapter序列文件，用于adapter污染检测
- `-limits <limits_file>`：指定limits文件，用于制定可接受的范围，例如序列长度、GC含量等
- `-extract`：提取原始的FastQC zip文件，而不进行分析
- `-q` 或 `--quiet`：静默模式，只输出错误消息



#### MultiQC[^5]

- `-h` 或 `--help` ：显示帮助信息。
- `-o <output_dir>` 或 `--outdir <output_dir>`：指定输出目录，将生成的报告文件保存到指定的目录中。
- `-c <config_file>` 或 `--config <config_file>`：指定配置文件，自定义报告生成的规则和设置。
- `-s` 或 `--fullnames`：显示完整的样本名称，而不仅仅是文件名部分。
- `--title <report_title>`：指定报告的标题。
- `-f` 或 `--force`：强制重新生成报告，覆盖已存在的报告文件。
- `--ignore <regexp>`：忽略与指定正则表达式匹配的文件。
- `--exclude <regexp>`：排除与指定正则表达式匹配的文件。
- `--no-ansi`：禁用ANSI转义序列，不使用彩色输出。
- `-q` 或 `--quiet`：静默模式，只输出错误消息。



### 2.3 质量检测

由于这两个软件都无法自动创建目录，因此需要手动创建输出目录：

```bash
mkdir result
```

对于单个文件，使用fastqc进行分析，如：

```bash
fastqc -o result -f fastq -t 8 raw_data/H1_1.fq.gz
```

即可得到分析结果：

![](/images/posts/trim_goal/fastC结果.png)

批量处理一个文件夹下的数据：

```bash
cd raw_data
ls *.gz |xargs fastqc -o ../result/ -t 8
```



同时，可以使用MultiQC对多个数据文件进行整合：

```bash
multiqc -o result/ result/
```

![](/images/posts/trim_goal/multiqc result.png)





## 三、数据清洗

### 3.1 软件安装

数据清洗使用的软件为Trim Galore和fastp，它前置依赖Cutadapt和FastQC

```bash
conda install cutadapt trim-galore fastp
```



### 3.2 参数含义

#### Trim Galore[^6]

- `--quality`：指定去除低质量reads的阈值，默认为20。 作用：去除质量低于指定阈值的reads
- `--length`：指定去除短reads的长度阈值，默认为20。 作用：去除长度低于指定阈值的reads
- `--stringency`：指定adapter剪切的严格程度，默认为1。 作用：调整adapter剪切的严格程度，值越高表示更严格的剪切
- `--paired`：指定输入的测序数据是否为配对的，默认为单端测序。 作用：指定处理的测序数据是否为配对的，以决定是否进行配对数据处理
- `--phred33`：：选择phred33或者phred64，表示测序平台使用的Phred quality score
- `--fastqc`：生成每个输入文件的质量评估报告，同时内部调用fastqc软件。 作用：生成测序数据的质量评估报告，以便进行质量控制
- `--fastqc_args "<ARGS>"` fastqc的参数
- `--gzip`：指定输出文件是否进行压缩，默认为否。 作用：选择是否对输出文件进行压缩，可以减小文件大小
- `--cores`：指定使用的CPU核心数，默认为1。 作用：指定trim-galore使用的CPU核心数，用于加速处理速度
- `--output_dir`：输入目录。需要提前建立目录，否则运行会报错



#### fastp[^7]

- `-i, --in1`：输入read1
- `-o, --out1`：输出read1
- `-I, --in2`：输入read2
- `-O, --out2`：输出read2
- `-A, --disable_ adpter_ trimming`：不过滤接头序列,默认过滤
- `-f, --trim_ front1`：去掉read1头部的几bp序列 ,默认为0
- `-t, --trim _tail1`：去掉read1尾部的几bp序列,默认为0
- `-F, --trim_ front2`：去掉read2头部的几bp序列,默认为0
- `-T, --trim_ front2`：去掉read2尾部的几bp序列,默认为0
- `-q,--qualified_ quality_phred`：质量值低于q的碱基将被过滤,默认为15
- `-I, --length_ required`：长度低于l的序列将被过滤,默认为15
- `-n, --n_ base_ limit`：序列中含N碱基多余n个将被过滤,默认为5
- `-5,-3`：开启滑窗质量裁剪
- `-W`：滑动窗口大小，默认4
- `-M`：滑窗裁剪平均质量，默认20
- `-j, --json`：生成可读的json文件
- `-h, --html`：生成html质控报告



### 3.3 清洗

#### 使用Trim Galore

```bash
mkdir clean_data
mkdir clean_result
```

对于单个文件：

```bash
trim_galore --paired --cores 2 --phred33 --length 35 --stringency 1 --quality 25 --gzip --fastqc_args "-o trim_result/ -f fastq -t 8" --output_dir after_trim/ raw_data/H1_1.fq.gz raw_data/H1_2.fq.gz
```



批量处理：

```bash
mkdir clean_data
mkdir clean_result

ls raw_data/*_1.fq.gz > 1
ls raw_data/*_2.fq.gz > 2

paste 1 2 >config

cat config | while read id
  do
    arr=($id)
    fq1=${arr[0]}
    fq2=${arr[1]}
    trim_galore --paired --cores 2 --phred33 --length 35 --stringency 1 --quality 25 --gzip --fastqc_args "-o clean_result/ -f fastq -t 8" --output_dir clean_data/  $fq1 $fq2
  done

rm 1
rm 2
rm config

multiqc -o clean_result/ clean_result/

echo "done"
```

批处理执行完之后即可得到清洗后的数据和报告：

![](/images/posts/trim_goal/after trim.png)



#### 使用fastp

```bash
rm -rf clean_data
rm -rf clean_result

mkdir clean_data
mkdir clean_result

cd raw_data/
ls *_1.fq.gz > 1
ls *_2.fq.gz > 2

paste 1 2 >config

cat config | while read id
  do
    arr=($id)
    fq1=${arr[0]}
    fq2=${arr[1]}
    fq1_clean=$(echo "$fq1" | sed 's/.fq.gz/_clean.fq.gz/')
    fq2_clean=$(echo "$fq2" | sed 's/.fq.gz/_clean.fq.gz/')
    fastp -i $fq1 -o ../clean_data/$fq1_clean -I $fq2 -O ../clean_data/$fq2_clean -f 15 -F 15 -q 25 -l 35 --thread=5  -5 -3
  done

rm 1
rm 2
rm config

cd ../clean_data
ls *_clean.fq.gz |xargs fastqc -o ../clean_result/ -t 8
cd ..
multiqc -o clean_result/ clean_result/

echo "done"
```



## 四、上游数据的比对计数

### 4.1 软件安装

#### hisat2

```bash
conda install hisat2 
```



#### samtools[^8]

```bash
sudo apt-get update
sudo apt-get install autoconf automake make gcc perl zlib1g-dev libbz2-dev liblzma-dev libcurl4-gnutls-dev libssl-dev libncurses5-dev

wget https://github.com/samtools/samtools/releases/download/1.18/samtools-1.18.tar.bz2
tar -xjvf samtools-1.18.tar.bz2
cd samtools-1.18
./configure
make
sudo make install
```



### 4.2 参数含义

#### hisat2

- `-x`：参考基因组索引文件的前缀。注意最后是/genome
- `-1`：双端测序结果的第一个文件。若有多组数据，使用逗号将文件分隔。Reads的长度可以不一致
- `-2`：双端测序结果的第二个文件。 若有多组数据，使用逗号将文件分隔，并且文件顺序要和-1参数对应。Reads的长度可以不一致
- `-S`：指定输出的SAM文件。
- `-t`：输出time
- `-p`：线程使用设置
- `-U`：单端数据文件。若有多组数据，使用逗号将文件分隔。可以和-1、 -2参数同时使用。 Reads的长度可以不一致
- `--sra-acc`：输入SRA登录号, 比如SRR353653, SRR353654。多组数据之间使用逗号分隔。HISAT将自动下载并识别数据类型，进行比对



#### samtools[^9]

- `view`：用于将sam文件转化为bam文件
  - `-b`：该参数设置输出 BAM 格式，默认下输出是 SAM 格式文件
  - `-h`：默认下输出的 sam 格式文件不带 header，该参数设定输出sam文件时带 header 信息 
  - `-H`：仅仅输出文件的头文件
  - `-S`：默认下输入是 BAM 文件，若是输入是 SAM 文件，则最好加该参数，否则有时候会报错。 
  - `-u`：该参数的使用需要有-b参数，能节约时间，但是需要更多磁盘空间。 
  - `-c`：仅输出匹配的统计记录 
  - `-L`：仅包括和bed文件存在overlap的reads
  - `-o`：输出文件的名称
  - `-F`：过滤flag，仅输出指定FLAG值的序列
  - `-q`：比对的最低质量值，一般认为20就为unique比对了，可以结合上述-bF参数使用使用提取特定的比对结果
  - `-@`：指使用的线程数
- `sort`：对bam文件进行排序
  - `-n`：设定排序方式按short reads的ID排序。默认下是按序列在fasta文件中的顺序（即header）和序列从左往右的位点排序。
  - `-m INT`：设置每个线程的最大内存，单位可以是K/M/G，默认是 768M。对于处理大数据时，如果内存够用，则设置大点的值，以节约时间。
  - `-t TAG`：按照TAG值排序
  - `-o FILE`：输出到文件中，加文件名
- `index`：建立索引，并生成bai文件
- `flagstat`：输出比对统计结果
  - `-@`：指使用的线程数



### 4.3 数据处理

#### get sam file

首先使用hisat2比对基因组得到sam文件，这里需要先下载参考基因组，因为我这里用的是人类细胞，所以使用hg38：

```bash
cd
mkdir -p reference/index/hisat
cd reference/index/hisat/
wget https://genome-idx.s3.amazonaws.com/hisat/hg38_genome.tar.gz
tar -zxvf hg38_genome.tar.gz
```

> 这玩意很大，下不下来也可以考虑使用别的方法下载后上传到服务器

下载并解压后文件如下：

![](/images/posts/trim_goal/索引文件.png)



接下来比对基因组

```bash
hisat2 --dta -t -x ../../reference/index/hisat/hg38/genome -1 H1_1_clean.fq.gz -2 H1_2_clean.fq.gz -p 4 -S hisat2_hg38data/H1.sam
```

> 这里genome是参考基因组文件的前缀



#### sam to bam

之后，使用samtools进行进一步操作，首先是将sam文件转化为bam文件：

```bash
samtools view -@ 8 -bS -o hisat2_hg38data/H1_1.bam hisat2_hg38data/H1_1.sam
```



#### sort and index

接下来对bam进行排序:

```bash
samtools sort -@ 8 -o hisat2_hg38data/H1_1.sort.bam hisat2_hg38data/H1_1.bam
```

之后对使用排序好的文件建立索引

```bash
samtools index hisat2_hg38data/H1_1.sort.bam
```

最后，将比对结果输入到文件中保存：

```bash
samtools flagstat -@ 8 -O json hisat2_hg38data/H1_1.sort.bam > hisat2_hg38data/H1_1.sort.flagsata
```



批量处理：

```bash
rm -rf hisat2_hg38data/
mkdir hisat2_hg38data

cd clean_data/
ls *1_clean.fq.gz > 1
ls *2_clean.fq.gz > 2
paste 1 2 >config

cat config | while read id
  do
    arr=($id)
    fq1=${arr[0]}
    fq2=${arr[1]}
    output=$(echo "$fq1" | sed 's/_clean.fq.gz/.sam/')
    echo "hisat2 --dta -t -x ../../reference/index/hisat/hg38/genome -1 $fq1 -2 $fq2 -p 4 -S ../hisat2_hg38data/$output"
    hisat2 --dta -t -x ../../reference/index/hisat/hg38/genome -1 $fq1 -2 $fq2 -p 4 -S ../hisat2_hg38data/$output
  done
  
rm 1 2 config

cd ../hisat2_hg38data

echo "start sam to bam..."
ls *.sam | xargs -I {} sh -c 'samtools view -@ 8 -bS -o $(basename {} .sam).bam {}'
echo "done, removing sam file..."
ls *.sam | xargs rm
echo "done"
tree

echo "star sorting..."
ls *.bam | xargs -I {} sh -c 'samtools sort -@ 8 -o $(basename {} .bam).sort.bam {}'
echo "done"
tree

echo "start indexing..."
ls *.sort.bam | xargs samtools index
echo "done"

echo "saving to flagsata..."
ls *.sort.bam | xargs -I {} sh -c 'samtools flagstat -@ 8 {} > $(basename {} .bam).flagstat'
echo "done"

multiqc ./
```



## 参考

[^1]: [https://learn.microsoft.com/en-us/windows/wsl/install](https://learn.microsoft.com/en-us/windows/wsl/install)
[^2]: [https://conda.io/projects/conda/en/stable/user-guide/install/index.html](https://conda.io/projects/conda/en/stable/user-guide/install/index.html)
[^3]: [https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/](https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/)

[^4]: [https://github.com/s-andrews/FastQC](https://github.com/s-andrews/FastQC)
[^5]: [https://multiqc.info/](https://multiqc.info/)
[^6]: [https://github.com/FelixKrueger/TrimGalore](https://github.com/FelixKrueger/TrimGalore)
[^7]: [https://github.com/OpenGene/fastp](https://github.com/OpenGene/fastp)
[^8]: [https://github.com/samtools/samtools/blob/develop/INSTALL](https://github.com/samtools/samtools/blob/develop/INSTALL)
[^9]: [samtools的安装和使用](https://www.jianshu.com/p/6b7a442d293f)
